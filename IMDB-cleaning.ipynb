{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2491ec-0410-43da-bfe7-c47f90a06bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order  Rating               Reviewer_Name  Topic          Date  \\\n",
      "0      1     NaN                LoveofLegacy    NaN  21 July 2023   \n",
      "1      2     NaN  aherdofbeautifulwildponies    NaN  26 July 2023   \n",
      "2      3     NaN                      imseeg    NaN  22 July 2023   \n",
      "3      4     NaN                    Natcat87    NaN  22 July 2023   \n",
      "4      5     NaN           G-Joshua-Benjamin    NaN  21 July 2023   \n",
      "\n",
      "                                              Review  \n",
      "0  Margot does the best with what she's given, bu...  \n",
      "1  Before making Barbie (2023),Greta Gerwigsingle...  \n",
      "2  The first reason to go see it:It's good fun. I...  \n",
      "3  As a woman that grew up with Barbie, I was ver...  \n",
      "4  I don't know if I put spoilers in here. I am s...  \n",
      "Cleaned IMDB data:\n",
      "   Order  Rating               Reviewer_Name  Topic          Date  \\\n",
      "0      1     NaN                LoveofLegacy    NaN  21 July 2023   \n",
      "1      2     NaN  aherdofbeautifulwildponies    NaN  26 July 2023   \n",
      "2      3     NaN                      imseeg    NaN  22 July 2023   \n",
      "3      4     NaN                    Natcat87    NaN  22 July 2023   \n",
      "4      5     NaN           G-Joshua-Benjamin    NaN  21 July 2023   \n",
      "\n",
      "                                              Review  \n",
      "0  margot does the best with what shes given but ...  \n",
      "1  before making barbie 2023greta gerwigsinglehan...  \n",
      "2  the first reason to go see itits good fun its ...  \n",
      "3  as a woman that grew up with barbie i was very...  \n",
      "4  i dont know if i put spoilers in here i am sup...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the IMDB reviews CSV file\n",
    "imdb_path = r'C:\\Users\\user\\Desktop\\Python\\Data\\IMDB_reviews.csv'\n",
    "df_imdb = pd.read_csv(imdb_path, encoding='utf-8')  # Adjust the encoding if needed\n",
    "\n",
    "# Display the first few rows to inspect the data\n",
    "print(df_imdb.head())\n",
    "\n",
    "# Handling missing values\n",
    "df_imdb.dropna(subset=['Review'], inplace=True)  # Drop rows with missing reviews\n",
    "\n",
    "# Remove duplicates based on the 'Review' column\n",
    "df_imdb.drop_duplicates(subset=['Review'], keep='first', inplace=True)\n",
    "\n",
    "# Preprocess text data (example: lowercase, remove special characters, etc.)\n",
    "df_imdb['Review'] = df_imdb['Review'].str.lower()\n",
    "df_imdb['Review'] = df_imdb['Review'].replace('[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_imdb_path = r'C:\\Users\\user\\Desktop\\Python\\Data\\IMDB_reviews_cleaned.csv'\n",
    "df_imdb.to_csv(cleaned_imdb_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned data\n",
    "print(\"Cleaned IMDB data:\")\n",
    "print(df_imdb.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0192ca8d-78be-4d08-af95-957e2f1a4bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Comment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Comment'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Apply preprocessing to the Comment column\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessed Comment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess_text)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Sentiment analysis using lexicon\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sentiment\u001b[39m(tokens):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Comment'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Download punkt resource\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load your dataset\n",
    "data_path = r'C:\\Users\\user\\Desktop\\Python\\Data\\IMDB_reviews_cleaned.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Updated lexicon\n",
    "positive_lexicon = [\n",
    "    \"empowering\", \"inspirational\", \"progressive\", \"inclusive\", \"uplifting\", \"positive representation\",\n",
    "    \"equality\", \"strong female characters\", \"feminist\", \"diverse\", \"encouraging\", \"supportive\", \"liberating\",\n",
    "    \"empowered\", \"enlightening\", \"forward-thinking\", \"trailblazing\", \"visionary\", \"progressive ideals\",\n",
    "    \"progressive values\", \"progressive messages\", \"progressive themes\", \"affirmative\", \"constructive\",\n",
    "    \"open-minded\", \"tolerant\", \"accepting\", \"respecting\", \"progressive portrayal\", \"empowerment message\",\n",
    "    \"inspirational content\", \"progressive outlook\", \"visionary\", \"trailblazing\", \"empowering\", \"innovative\",\n",
    "    \"optimistic\", \"hopeful\", \"upbeat\", \"empowering\", \"encouragement\", \"positive vibes\", \"positive energy\"\n",
    "]\n",
    "\n",
    "negative_lexicon = [\n",
    "    \"anti-feminist\", \"stereotypical\", \"sexist\", \"offensive\", \"controversial\", \"backward\", \"discriminatory\",\n",
    "    \"problematic\", \"regressive\", \"offensive portrayal\", \"stereotype reinforcement\", \"demeaning\", \"insensitive\",\n",
    "    \"disparaging\", \"offensive language\", \"negative representation\", \"bias\", \"pessimistic\", \"undermining\",\n",
    "    \"offensive content\", \"harmful\", \"offensive messages\", \"offensive themes\", \"counterproductive\", \"oppressive\",\n",
    "    \"repressive\", \"unprogressive\", \"unenlightened\", \"backward portrayal\", \"negative outlook\", \"depressing\",\n",
    "    \"disheartening\", \"discouraging\", \"hopeless\", \"pessimistic\", \"negative vibes\", \"negative energy\"\n",
    "]\n",
    "\n",
    "neutral_lexicon = [\n",
    "    \"movie\", \"character\", \"plot\", \"animation\", \"storyline\", \"director\", \"cinematography\", \"production\", \"release\",\n",
    "    \"audience\", \"entertainment\", \"screenplay\", \"cinematic\", \"cinematic elements\", \"visuals\", \"soundtrack\", \"editing\",\n",
    "    \"artistic\", \"technical aspects\", \"filmography\", \"performance\", \"acting\", \"performers\", \"cast\", \"cinematic techniques\",\n",
    "    \"production quality\", \"film industry\", \"film creation\", \"film direction\", \"film release\", \"viewer experience\",\n",
    "    \"audience response\", \"cinematic presentation\", \"generic\", \"standard\", \"typical\", \"common\", \"average\", \"ordinary\",\n",
    "    \"conventional\", \"usual\", \"routine\", \"traditional\", \"regular\", \"normal\", \"ordinary\"\n",
    "]\n",
    "\n",
    "# Tokenization and stemming\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the value is a string\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        stemmed_tokens = [ps.stem(token) for token in tokens]\n",
    "        return stemmed_tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply preprocessing to the Comment column\n",
    "df['Processed Comment'] = df['Comment'].apply(preprocess_text)\n",
    "\n",
    "# Sentiment analysis using lexicon\n",
    "def get_sentiment(tokens):\n",
    "    positive_count = sum(token in positive_lexicon for token in tokens)\n",
    "    negative_count = sum(token in negative_lexicon for token in tokens)\n",
    "\n",
    "    if positive_count > negative_count:\n",
    "        return 'Positive'\n",
    "    elif positive_count < negative_count:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis to each row\n",
    "df['Sentiment'] = df['Processed Comment'].apply(get_sentiment)\n",
    "\n",
    "# Save the results\n",
    "output_path = r'C:\\Users\\user\\Desktop\\Miki\\Data\\Youtube_20231130\\Youtube-sentiment_results.csv'\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890e63e1-fb75-4b23-9bad-e3e00442229a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (3301388837.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 44\u001b[1;36m\u001b[0m\n\u001b[1;33m    'Neutral': list(set([\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Download punkt resource\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load your dataset\n",
    "data_path = r'C:\\Users\\user\\Desktop\\Python\\Data\\IMDB_reviews_cleaned.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Updated lexicon\n",
    "positive_lexicon = [\n",
    "    \"empowering\", \"inspirational\", \"progressive\", \"inclusive\", \"uplifting\", \"positive representation\",\n",
    "    \"equality\", \"strong female characters\", \"feminist\", \"diverse\", \"encouraging\", \"supportive\", \"liberating\",\n",
    "    \"empowered\", \"enlightening\", \"forward-thinking\", \"trailblazing\", \"visionary\", \"progressive ideals\",\n",
    "    \"progressive values\", \"progressive messages\", \"progressive themes\", \"affirmative\", \"constructive\",\n",
    "    \"open-minded\", \"tolerant\", \"accepting\", \"respecting\", \"progressive portrayal\", \"empowerment message\",\n",
    "    \"inspirational content\", \"progressive outlook\", \"visionary\", \"trailblazing\", \"empowering\", \"innovative\",\n",
    "    \"optimistic\", \"hopeful\", \"upbeat\", \"empowering\", \"encouragement\", \"positive vibes\", \"positive energy\"\n",
    "]\n",
    "\n",
    "negative_lexicon = [\n",
    "    \"anti-feminist\", \"stereotypical\", \"sexist\", \"offensive\", \"controversial\", \"backward\", \"discriminatory\",\n",
    "    \"problematic\", \"regressive\", \"offensive portrayal\", \"stereotype reinforcement\", \"demeaning\", \"insensitive\",\n",
    "    \"disparaging\", \"offensive language\", \"negative representation\", \"bias\", \"pessimistic\", \"undermining\",\n",
    "    \"offensive content\", \"harmful\", \"offensive messages\", \"offensive themes\", \"counterproductive\", \"oppressive\",\n",
    "    \"repressive\", \"unprogressive\", \"unenlightened\", \"backward portrayal\", \"negative outlook\", \"depressing\",\n",
    "    \"disheartening\", \"discouraging\", \"hopeless\", \"pessimistic\", \"negative vibes\", \"negative energy\"\n",
    "]\n",
    "\n",
    "neutral_lexicon = [\n",
    "    \"movie\", \"character\", \"plot\", \"animation\", \"storyline\", \"director\", \"cinematography\", \"production\", \"release\",\n",
    "    \"audience\", \"entertainment\", \"screenplay\", \"cinematic\", \"cinematic elements\", \"visuals\", \"soundtrack\", \"editing\",\n",
    "    \"artistic\", \"technical aspects\", \"filmography\", \"performance\", \"acting\", \"performers\", \"cast\", \"cinematic techniques\",\n",
    "    \"production quality\", \"film industry\", \"film creation\", \"film direction\", \"film release\", \"viewer experience\",\n",
    "    \"audience response\", \"cinematic presentation\", \"generic\", \"standard\", \"typical\", \"common\", \"average\", \"ordinary\",\n",
    "    \"conventional\", \"usual\", \"routine\", \"traditional\", \"regular\", \"normal\", \"ordinary\"\n",
    "]\n",
    "\n",
    "# Tokenization and stemming\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the value is a string\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        stemmed_tokens = [ps.stem(token) for token in tokens]\n",
    "        return stemmed_tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply preprocessing to the Review column\n",
    "df['Processed Comment'] = df['Review'].apply(preprocess_text)\n",
    "\n",
    "# Sentiment analysis using lexicon\n",
    "def get_sentiment(tokens):\n",
    "    positive_count = sum(token in positive_lexicon for token in tokens)\n",
    "    negative_count = sum(token in negative_lexicon for token in tokens)\n",
    "\n",
    "    if positive_count > negative_count:\n",
    "        return 'Positive'\n",
    "    elif positive_count < negative_count:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis to each row\n",
    "df['Sentiment'] = df['Processed Comment'].apply(get_sentiment)\n",
    "\n",
    "# Save the results\n",
    "output_path = r'C:\\Users\\user\\Desktop\\Miki\\Data\\Youtube_20231130\\Youtube-sentiment_results.csv'\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91deeb1-ea08-4dbb-aac4-e7beb3befbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Processed Comment Sentiment\n",
      "774  ['thi', 'movi', 'ha', 'fun', 'aesthet', 'and',...  Positive\n",
      "597  ['it', 'truli', 'surpris', 'me', 'how', 'greta...   Neutral\n",
      "844  ['a', 'stori', 'that', 'explor', 'mattel', 'th...   Neutral\n",
      "883  ['becaus', 'of', 'some', 'review', 'i', 'thoug...   Neutral\n",
      "68   ['thi', 'movi', 'is', 'mani', 'thing', 'one', ...   Neutral\n",
      "268  ['greta', 'gerwig', 'barbi', 'is', 'a', 'stun'...   Neutral\n",
      "828  ['i', 'did', 'have', 'a', 'veri', 'high', 'exp...   Neutral\n",
      "11   ['i', 'do', 'not', 'usual', 'write', 'review',...   Neutral\n",
      "69   ['i', 'saw', 'thi', 'movi', 'tonight', 'and', ...  Positive\n",
      "495  ['it', 'ha', 'great', 'moment', 'the', 'begin'...   Neutral\n",
      "392  ['barbi', 'is', 'a', 'movi', 'that', 'you', 's...   Neutral\n",
      "868  ['get', 'you', 'a', 'typic', 'hollywood', 'mov...   Neutral\n",
      "924  ['i', 'realli', 'want', 'to', 'like', 'thi', '...  Positive\n",
      "55   ['barbi', 'margot', 'robbi', 'travel', 'from',...  Positive\n",
      "615  ['it', 'ha', 'it', 'great', 'moment', 'like', ...   Neutral\n",
      "908  ['oh', 'my', 'glob', 'i', 'freakin', 'love', '...   Neutral\n",
      "872  ['thi', 'movi', 'wa', 'everyth', 'that', 'wa',...  Positive\n",
      "337  ['i', 'absolut', 'love', 'it', 'margot', 'robb...   Neutral\n",
      "208  ['ruth', 'handler', 'the', 'inventor', 'of', '...   Neutral\n",
      "298  ['the', 'longawait', 'and', 'wellpublic', 'bar...   Neutral\n",
      "\n",
      "Sentiment Distribution:\n",
      "Neutral     839\n",
      "Positive     91\n",
      "Negative     10\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Sentiment Percentages:\n",
      "Positive: 9.68%\n",
      "Neutral: 89.26%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the sentiment results CSV\n",
    "sentiment_results_path = r'C:\\Users\\user\\Desktop\\Python\\Data\\IMDB-sentiment_results.csv'\n",
    "df_sentiment = pd.read_csv(sentiment_results_path)\n",
    "\n",
    "# Display a sample of comments and their sentiments\n",
    "sample_comments = df_sentiment.sample(20)  # Adjust the sample size as needed\n",
    "print(sample_comments[['Comment', 'Sentiment']])\n",
    "\n",
    "# Analyze sentiment distribution\n",
    "sentiment_distribution = df_sentiment['Sentiment'].value_counts()\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(sentiment_distribution)\n",
    "\n",
    "# Calculate sentiment percentages\n",
    "total_comments = len(df_sentiment)\n",
    "positive_percentage = (sentiment_distribution['Positive'] / total_comments) * 100\n",
    "neutral_percentage = (sentiment_distribution['Neutral'] / total_comments) * 100\n",
    "negative_percentage = (sentiment_distribution['Negative'] / total_comments) * 100\n",
    "\n",
    "print(\"\\nSentiment Percentages:\")\n",
    "print(f\"Positive: {positive_percentage:.2f}%\")\n",
    "print(f\"Neutral: {neutral_percentage:.2f}%\")\n",
    "print(f\"Negative: {negative_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a00a63-39f0-4d5e-ad2e-c6a6b78c2e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13780\\1879615652.py:7: DtypeWarning: Columns (15,16,17,18,19,20,21,22,23,24,25,26,27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Words:\n",
      "the      110881\n",
      "and       61389\n",
      "a         59887\n",
      "to        59371\n",
      "i         55793\n",
      "it        53648\n",
      "of        42383\n",
      "is        40025\n",
      "movi      36766\n",
      "that      36696\n",
      "thi       34099\n",
      "barbi     32436\n",
      "in        30174\n",
      "wa        23909\n",
      "be        23714\n",
      "you       21827\n",
      "for       21692\n",
      "but       17227\n",
      "like      16627\n",
      "with      16114\n",
      "they      15892\n",
      "not       15302\n",
      "are       15158\n",
      "have      14907\n",
      "as        14495\n",
      "so        14395\n",
      "just      13581\n",
      "on        12291\n",
      "about     12091\n",
      "ken       11328\n",
      "all       11001\n",
      "my        10750\n",
      "women     10651\n",
      "men       10107\n",
      "what       9936\n",
      "me         9559\n",
      "watch      8946\n",
      "how        8734\n",
      "see        8703\n",
      "at         8545\n",
      "if         8187\n",
      "think      8106\n",
      "your       8071\n",
      "go         7591\n",
      "or         7449\n",
      "world      7396\n",
      "film       7394\n",
      "she        7326\n",
      "im         7307\n",
      "make       7013\n",
      "dtype: int64\n",
      "Positive Words:\n",
      "['great']\n",
      "\n",
      "Negative Words:\n",
      "['bad', 'awful', 'hate']\n",
      "\n",
      "Neutral Words:\n",
      "['movie', 'character', 'plot', 'director', 'film', 'screenplay', 'soundtrack', 'cast']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load your dataset\n",
    "data_path = r'C:\\Users\\user\\Desktop\\Miki\\Data\\Youtube_20231130\\Youtube-final_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Tokenization and stemming\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the value is a string\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        stemmed_tokens = [ps.stem(token) for token in tokens]\n",
    "        return stemmed_tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply preprocessing to the Comment column\n",
    "df['Processed Comment'] = df['Comment'].apply(preprocess_text)\n",
    "\n",
    "# Flatten the list of tokenized comments\n",
    "all_tokens = [token for comment_tokens in df['Processed Comment'] for token in comment_tokens]\n",
    "\n",
    "# Calculate word frequencies\n",
    "word_frequencies = pd.Series(all_tokens).value_counts()\n",
    "\n",
    "# Display the top words\n",
    "top_words = word_frequencies.head(50)\n",
    "print(\"Top Words:\")\n",
    "print(top_words)\n",
    "\n",
    "# Manually classify words into positive, negative, or neutral\n",
    "word_lexicon = {\n",
    "    'Positive': [\"inspirational\", \"positive\", \"uplifting\", \"great\", \"excellent\", \"innovative\", \"inspiring\", \"fantastic\", \"amazing\", \"awesome\"],\n",
    "    'Negative': [\"offensive\", \"controversial\", \"regressive\", \"dreadful\", \"terrible\", \"horrible\", \"bad\", \"disappointing\", \"awful\", \"hate\"],\n",
    "    'Neutral': [\"movie\", \"character\", \"plot\", \"animation\", \"storyline\", \"director\", \"production\", \"release\", \"audience\", \"film\", \"entertainment\", \"screenplay\", \"cinematic\", \"visuals\", \"soundtrack\", \"editing\", \"artistic\", \"performance\", \"acting\", \"cast\"]\n",
    "}\n",
    "\n",
    "# Classify words based on lexicons\n",
    "classified_words = {sentiment: [word for word in words if word in word_frequencies.index] for sentiment, words in word_lexicon.items()}\n",
    "\n",
    "# Display the classified words\n",
    "for sentiment, words in classified_words.items():\n",
    "    print(f\"{sentiment} Words:\")\n",
    "    print(words)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec7f5f1-1d93-4489-99e6-b868cacf7604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the sentiment results CSV\n",
    "sentiment_results_path = r'C:\\Users\\user\\Desktop\\Python\\Data\\IMDB-sentiment_results.csv'\n",
    "df_sentiment = pd.read_csv(sentiment_results_path)\n",
    "\n",
    "# Display a sample of comments and their sentiments\n",
    "sample_comments = df_sentiment.sample(20)  # Adjust the sample size as needed\n",
    "print(sample_comments[['Comment', 'Sentiment']])\n",
    "\n",
    "# Analyze sentiment distribution\n",
    "sentiment_distribution = df_sentiment['Sentiment'].value_counts()\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(sentiment_distribution)\n",
    "\n",
    "# Calculate sentiment percentages\n",
    "total_comments = len(df_sentiment)\n",
    "positive_percentage = (sentiment_distribution['Positive'] / total_comments) * 100\n",
    "neutral_percentage = (sentiment_distribution['Neutral'] / total_comments) * 100\n",
    "negative_percentage = (sentiment_distribution['Negative'] / total_comments) * 100\n",
    "\n",
    "print(\"\\nSentiment Percentages:\")\n",
    "print(f\"Positive: {positive_percentage:.2f}%\")\n",
    "print(f\"Neutral: {neutral_percentage:.2f}%\")\n",
    "print(f\"Negative: {negative_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b2612b-3a71-4b17-aa56-c8bd368d797c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Processed Comment Sentiment\n",
      "284  ['it', 'wa', 'nostalg', 'hilari', 'esthet', 'o...   Neutral\n",
      "368  ['so', 'it', 'look', 'and', 'sound', 'amaz', '...   Neutral\n",
      "603  ['i', 'had', 'no', 'idea', 'what', 'to', 'expe...  Positive\n",
      "406  ['the', 'film', 'wa', 'good', 'and', 'there', ...  Positive\n",
      "391  ['thi', 'movi', 'wa', 'fantast', 'leav', 'it',...  Positive\n",
      "698  ['thi', 'movi', 'wa', 'such', 'great', 'experi...  Positive\n",
      "118  ['have', 'seen', 'thi', 'movi', 'twice', 'now'...  Positive\n",
      "126  ['honestli', 'it', 'ryan', 'gosl', 'that', 'ma...  Positive\n",
      "250  ['a', 'confus', 'misfir', 'tediou', 'and', 'pr...   Neutral\n",
      "623  ['i', 'realli', 'like', 'the', 'movi', 'withou...  Positive\n",
      "346  ['such', 'a', 'silli', 'beauti', 'wonder', 'mo...  Negative\n",
      "430  ['i', 'wa', 'think', 'that', 'barbi', 'wa', 'g...  Positive\n",
      "22   ['i', 'person', 'expect', 'the', 'movi', 'to',...  Positive\n",
      "313  ['i', 'will', 'keep', 'thi', 'as', 'spoiler', ...   Neutral\n",
      "330  ['we', 'saw', 'the', 'movi', 'becaus', 'everyo...  Negative\n",
      "731  ['have', 'you', 'watch', 'barbiey', 'i', 'am',...  Positive\n",
      "298  ['the', 'longawait', 'and', 'wellpublic', 'bar...  Positive\n",
      "823  ['me', 'and', 'my', 'wifey', 'watch', 'it', 'a...  Positive\n",
      "33   ['i', 'love', 'barbi', 'grow', 'up', 'and', 'e...  Positive\n",
      "532  ['thi', 'movi', 'wa', 'definit', 'made', 'for'...  Positive\n",
      "\n",
      "Sentiment Distribution:\n",
      "Positive    787\n",
      "Neutral     135\n",
      "Negative     18\n",
      "Name: Sentiment, dtype: int64\n",
      "\n",
      "Sentiment Percentages:\n",
      "Positive: 83.72%\n",
      "Neutral: 14.36%\n",
      "Negative: 1.91%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the sentiment results CSV\n",
    "sentiment_results_path = r'C:\\Users\\user\\Desktop\\Miki\\Data\\Youtube_20231130\\IMDB-sentiment_results.csv'\n",
    "df_sentiment = pd.read_csv(sentiment_results_path)\n",
    "\n",
    "# Display a sample of comments and their sentiments\n",
    "sample_comments = df_sentiment.sample(20)  # Adjust the sample size as needed\n",
    "print(sample_comments[['Processed Comment', 'Sentiment']])\n",
    "\n",
    "# Analyze sentiment distribution\n",
    "sentiment_distribution = df_sentiment['Sentiment'].value_counts()\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(sentiment_distribution)\n",
    "\n",
    "# Calculate sentiment percentages\n",
    "total_comments = len(df_sentiment)\n",
    "positive_percentage = (sentiment_distribution['Positive'] / total_comments) * 100\n",
    "neutral_percentage = (sentiment_distribution['Neutral'] / total_comments) * 100\n",
    "negative_percentage = (sentiment_distribution['Negative'] / total_comments) * 100\n",
    "\n",
    "print(\"\\nSentiment Percentages:\")\n",
    "print(f\"Positive: {positive_percentage:.2f}%\")\n",
    "print(f\"Neutral: {neutral_percentage:.2f}%\")\n",
    "print(f\"Negative: {negative_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc25dd73-9383-4235-9764-54e7cfad62ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
